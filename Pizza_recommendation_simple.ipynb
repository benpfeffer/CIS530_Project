{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567627aa",
   "metadata": {},
   "source": [
    "# Pizza_recommendation_simple.ipynb file for Cart-Based Pizza Recommendation System\n",
    "## Ben Pfeffer, Andrew Anctil, Bradon Wetzel\n",
    "## CIS 530 - Advanced Data Mining - Professor Thomas Gyeera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e8b700",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109aac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/m9393pr55dd73xt9k6s7jnlm0000gn/T/ipykernel_81413/2023834412.py:2: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
      "  from pandas_profiling import ProfileReport\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c463d1",
   "metadata": {},
   "source": [
    "### Load data (downloaded from kaggle) and perform data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b229f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "od = pd.read_csv(\"pizza_sales/order_details.csv\")\n",
    "o = pd.read_csv(\"pizza_sales/orders.csv\")\n",
    "pt = pd.read_csv(\"pizza_sales/pizza_types.csv\", encoding= 'unicode_escape') # codec decode error\n",
    "p = pd.read_csv(\"pizza_sales/pizzas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ec86b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the datasets\n",
    "ood = o.set_index('order_id').join(od.set_index('order_id')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ece838",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt = p.set_index('pizza_type_id').join(pt.set_index('pizza_type_id')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df3a7ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ood.set_index('pizza_id').join(ppt.set_index('pizza_id')).reset_index().sort_values(by=\"order_details_id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e98e4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_details_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48620.000000</td>\n",
       "      <td>48620.000000</td>\n",
       "      <td>48620.000000</td>\n",
       "      <td>48620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10701.479761</td>\n",
       "      <td>24310.500000</td>\n",
       "      <td>1.019622</td>\n",
       "      <td>16.494132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6180.119770</td>\n",
       "      <td>14035.529381</td>\n",
       "      <td>0.143077</td>\n",
       "      <td>3.621789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5337.000000</td>\n",
       "      <td>12155.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10682.500000</td>\n",
       "      <td>24310.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16100.000000</td>\n",
       "      <td>36465.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21350.000000</td>\n",
       "      <td>48620.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>35.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           order_id  order_details_id      quantity         price\n",
       "count  48620.000000      48620.000000  48620.000000  48620.000000\n",
       "mean   10701.479761      24310.500000      1.019622     16.494132\n",
       "std     6180.119770      14035.529381      0.143077      3.621789\n",
       "min        1.000000          1.000000      1.000000      9.750000\n",
       "25%     5337.000000      12155.750000      1.000000     12.750000\n",
       "50%    10682.500000      24310.500000      1.000000     16.500000\n",
       "75%    16100.000000      36465.250000      1.000000     20.250000\n",
       "max    21350.000000      48620.000000      4.000000     35.950000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the data using the describe() function\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f549947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0286569b23844048a2a2f5d4d320dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminpfeffer/no/envs/mlp/lib/python3.8/site-packages/multimethod/__init__.py:315: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03414bc320e480c923606176b75d708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bf7508980b4d9d8763b418d7744b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2f9fbc456448fba638679bb5ca4e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a profile report (pizzaData.html output)\n",
    "prof = ProfileReport(df)\n",
    "prof.to_file(output_file='pizzaData.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6c3061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the order and count pizzas per order\n",
    "groups = df.groupby(\"order_id\").agg({\"pizza_type_id\":\"count\"}).reset_index()\n",
    "# Select where more than 1 pizza\n",
    "multiOrders = groups[groups.pizza_type_id>1].order_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d0372be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the multi-order dataframe\n",
    "moDf = df[df.order_id.isin(multiOrders)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb0257",
   "metadata": {},
   "source": [
    "## Ways to recommend:\n",
    "### 1) User Similarity (similar prices and times)\n",
    "### 2) Association (similar orders)\n",
    "### 3) Item-item similarity * noted as best way from class notes\n",
    "### 4) Popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2376551",
   "metadata": {},
   "source": [
    "### From class notes, best recommendation type is item to item\n",
    "### In our case, this means pizzas that go with pizzas, not order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd915fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the data\n",
    "simple = moDf[[\"order_id\", \"quantity\", \"pizza_type_id\"]]\n",
    "copyDf = simple.copy()\n",
    "# Set all quantities to 1\n",
    "copyDf['quantity'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d261c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "copyDf = copyDf.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b203199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table to get the item to item dataframe that we need\n",
    "itemitem = copyDf.pivot(index='pizza_type_id', columns='order_id', values='quantity').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc133c6a",
   "metadata": {},
   "source": [
    "### Determine the best metric to use with Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9df9879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics found from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html\n",
    "metric_list = ['cityblock',\n",
    " 'cosine',\n",
    " 'euclidean',\n",
    " 'l2',\n",
    " 'l1',\n",
    " 'manhattan',\n",
    " 'nan_euclidean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d54134",
   "metadata": {},
   "source": [
    "### Use training, validation and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2596c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose data to extract list of pizzas\n",
    "ii = itemitem.transpose().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6ad7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of pizzas\n",
    "pizza_types = itemitem.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aae25b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cityblock\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "cosine\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "euclidean\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "l2\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "l1\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "manhattan\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "nan_euclidean\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# For all metrics:\n",
    "oo_jacs_val = []\n",
    "oo_cos_val = []\n",
    "oo_lev_val = []\n",
    "oo_rmse_val = []\n",
    "oo_mae_val = []\n",
    "\n",
    "oo_jacs = []\n",
    "oo_cos = []\n",
    "oo_lev = []\n",
    "oo_rmse = []\n",
    "oo_mae = []\n",
    "\n",
    "# Iterate through metric list for NN\n",
    "for metric in metric_list:\n",
    "    print(metric)\n",
    "\n",
    "    # 100 random splits, independent on previous splits\n",
    "    plot_jacs_val = []\n",
    "    plot_cos_val = []\n",
    "    plot_lev_val = []\n",
    "    plot_rmse_val = []\n",
    "    plot_mae_val = []\n",
    "\n",
    "    plot_jacs = []\n",
    "    plot_cos = []\n",
    "    plot_lev = []\n",
    "    plot_rmse = []\n",
    "    plot_mae = []\n",
    "\n",
    "    # Iterate through 100 random trials of sampling\n",
    "    for i in range(100):\n",
    "        if(i%20==0):\n",
    "            print(i)\n",
    "        # Select the random sampled training set, validation set, and testing set\n",
    "        train_size = 0.70\n",
    "        val_size = 0.15\n",
    "        ii_train = ii.sample(n=int(np.floor(len(ii)*train_size)))\n",
    "        remain = ii[~ii['order_id'].isin(ii_train[\"order_id\"])]\n",
    "        ii_val = remain.sample(n=int(np.floor(len(remain)*val_size)))\n",
    "        ii_test = remain[~remain['order_id'].isin(ii_val[\"order_id\"])]\n",
    "\n",
    "        # Reformat the data\n",
    "        ii_train = ii_train.set_index('order_id').transpose()\n",
    "        ii_val = ii_val.set_index('order_id').transpose()\n",
    "        ii_test = ii_test.set_index('order_id').transpose()\n",
    "\n",
    "        # Fit the nearest neighbors model using cosine similarity on the training set\n",
    "        knn = NearestNeighbors(metric=metric, algorithm='brute')\n",
    "        knn.fit(ii_train.values)\n",
    "        distances_train, indices_train = knn.kneighbors(ii_train.values, n_neighbors=len(ii_train))\n",
    "\n",
    "\n",
    "        # Make n recommendations and calculate metrics\n",
    "        ns = np.arange(1,15)\n",
    "        all_mins = [] # store the minimum similarities\n",
    "        \n",
    "        # Store the metrics for each n\n",
    "        outer_jacs_val = []\n",
    "        outer_cos_val = []\n",
    "        outer_lev_val = []\n",
    "        outer_rmse_val = []\n",
    "        outer_mae_val = []\n",
    "        outer_jacs = []\n",
    "        outer_cos = []\n",
    "        outer_lev = []\n",
    "        outer_rmse = []\n",
    "        outer_mae = []\n",
    "        # Iterate through all ns\n",
    "        for n in ns:\n",
    "            all_jacs_val = [] # jaccard similarity\n",
    "            all_cos_val = [] # cosine similarity\n",
    "            all_lev_val = [] # lev distance = edit distance\n",
    "            all_rmse_val = [] # RMSE\n",
    "            all_mae_val = [] # mae\n",
    "            all_jacs = [] # jaccard similarity\n",
    "            all_cos = [] # cosine similarity\n",
    "            all_lev = [] # lev distance = edit distance\n",
    "            all_rmse = [] # RMSE\n",
    "            all_mae = [] # mae\n",
    "            idx = 0\n",
    "            # Iterate through all pizza types\n",
    "            for i in pizza_types:\n",
    "                # Store the orders of current pizza as dataframe\n",
    "                pizza_df_val = ii_val.transpose()[ii_val.transpose()[i]==1]\n",
    "                pizza_df = ii_test.transpose()[ii_test.transpose()[i]==1]\n",
    "\n",
    "                # Find the counts of true orders\n",
    "                counts_val = []\n",
    "                for i in pizza_df_val.columns:\n",
    "                    counts_val.append(sum(pizza_df_val[i]))\n",
    "                counts = []\n",
    "                for i in pizza_df.columns:\n",
    "                    counts.append(sum(pizza_df[i]))\n",
    "\n",
    "                # Create dataframe to store this info\n",
    "                result_df_val = pd.DataFrame()\n",
    "                result_df_val[\"Pizza\"] = pizza_df_val.columns\n",
    "                result_df_val[\"Count\"] = counts_val\n",
    "                # Create dataframe to store this info\n",
    "                result_df = pd.DataFrame()\n",
    "                result_df[\"Pizza\"] = pizza_df.columns\n",
    "                result_df[\"Count\"] = counts\n",
    "\n",
    "                # Extract the model results\n",
    "                curr = indices_train[idx]\n",
    "                dist = distances_train[idx]\n",
    "                idx += 1\n",
    "\n",
    "                # Extract predicted vs true values\n",
    "                recPizzas = [pizza_types[j] for j in curr[1:n+1]]\n",
    "                truePizzas_val = list(result_df_val.sort_values(\"Count\", ascending=False).Pizza.iloc[:n].values)\n",
    "                truePizzas = list(result_df.sort_values(\"Count\", ascending=False).Pizza.iloc[:n].values)\n",
    "\n",
    "                # Get jaccard similarity\n",
    "                # For val set\n",
    "                correct_val = [i for i in recPizzas if i in truePizzas_val]\n",
    "                combined = recPizzas.copy()\n",
    "                combined.extend(truePizzas_val)\n",
    "                union_val = set(combined)\n",
    "                jac = len(correct_val)/len(union_val)\n",
    "                all_jacs_val.append(jac)\n",
    "\n",
    "                # For test set\n",
    "                correct = [i for i in recPizzas if i in truePizzas]\n",
    "                combined = recPizzas.copy()\n",
    "                combined.extend(truePizzas)\n",
    "                union = set(combined)\n",
    "                jac = len(correct)/len(union)\n",
    "                all_jacs.append(jac)\n",
    "\n",
    "\n",
    "                # Get cosine similarity of results\n",
    "                # Processing assistance found: https://stackoverflow.com/questions/28819272/python-how-to-calculate-the-cosine-similarity-of-two-word-lists\n",
    "                # count word occurrences\n",
    "                a_vals = Counter(recPizzas)\n",
    "                b_vals_val = Counter(truePizzas_val)\n",
    "                b_vals = Counter(truePizzas)\n",
    "\n",
    "                # convert to word-vectors - val\n",
    "                words  = list(a_vals.keys() | b_vals_val.keys())\n",
    "                a_vect = [a_vals.get(word, 0) for word in words]\n",
    "                b_vect = [b_vals_val.get(word, 0) for word in words]  \n",
    "                cos = cosine_similarity(np.array(a_vect).reshape(1, -1), np.array(b_vect).reshape(1, -1))\n",
    "                all_cos_val.append(cos)\n",
    "                \n",
    "                # For test set\n",
    "                words  = list(a_vals.keys() | b_vals.keys())\n",
    "                a_vect = [a_vals.get(word, 0) for word in words]\n",
    "                b_vect = [b_vals.get(word, 0) for word in words]  \n",
    "                cos = cosine_similarity(np.array(a_vect).reshape(1, -1), np.array(b_vect).reshape(1, -1))\n",
    "                all_cos.append(cos)\n",
    "\n",
    "                # Levenshtein distance\n",
    "                all_lev_val.append(levenshtein_distance(truePizzas_val, recPizzas))\n",
    "                all_lev.append(levenshtein_distance(truePizzas, recPizzas))\n",
    "\n",
    "                # Ranked rmse\n",
    "                # For val set\n",
    "                # Get ascending counts as true ranks\n",
    "                allTruePizzas = list(result_df_val.sort_values(\"Count\", ascending=False).Pizza.values)\n",
    "                # Store the union\n",
    "                compareDf_val = pd.DataFrame()\n",
    "                compareDf_val[\"Pizza\"] = list(union_val)\n",
    "                rec_ranks = []\n",
    "                true_ranks = []\n",
    "                # Iterate through the union and append ranks\n",
    "                for pizza in union_val:\n",
    "                    try:\n",
    "                        rec_ranks.append(recPizzas.index(pizza)+1)\n",
    "                    except:\n",
    "                        rec_ranks.append(np.nan)\n",
    "                    try:\n",
    "                        true_ranks.append(allTruePizzas.index(pizza))\n",
    "                    except:\n",
    "                        true_ranks.append(np.nan)\n",
    "                # Store the ranks\n",
    "                compareDf_val[\"RecRank\"] = rec_ranks\n",
    "                compareDf_val[\"TrueRank\"] = true_ranks\n",
    "                # Drop when not applicable\n",
    "                compareDf_val = compareDf_val.dropna()\n",
    "                # Calculate RMSE\n",
    "                rmse = sqrt(mean_squared_error(compareDf_val.TrueRank, compareDf_val.RecRank))\n",
    "                all_rmse_val.append(rmse)\n",
    "\n",
    "                # For test set\n",
    "                # Get ascending counts as true ranks\n",
    "                allTruePizzas = list(result_df.sort_values(\"Count\", ascending=False).Pizza.values)\n",
    "                # Store the union\n",
    "                compareDf = pd.DataFrame()\n",
    "                compareDf[\"Pizza\"] = list(union)\n",
    "                rec_ranks = []\n",
    "                true_ranks = []\n",
    "                # Iterate through the union and append ranks\n",
    "                for pizza in union:\n",
    "                    try:\n",
    "                        rec_ranks.append(recPizzas.index(pizza)+1)\n",
    "                    except:\n",
    "                        rec_ranks.append(np.nan)\n",
    "                    try:\n",
    "                        true_ranks.append(allTruePizzas.index(pizza))\n",
    "                    except:\n",
    "                        true_ranks.append(np.nan)\n",
    "                # Store the ranks\n",
    "                compareDf[\"RecRank\"] = rec_ranks\n",
    "                compareDf[\"TrueRank\"] = true_ranks\n",
    "                # Drop when not applicable\n",
    "                compareDf = compareDf.dropna()\n",
    "                # Calculate RMSE\n",
    "                rmse = sqrt(mean_squared_error(compareDf.TrueRank, compareDf.RecRank))\n",
    "                all_rmse.append(rmse)\n",
    "\n",
    "                # Calculate MAE score for val and test\n",
    "                mae = mean_absolute_error(compareDf.TrueRank, compareDf.RecRank)\n",
    "                all_mae.append(mae)\n",
    "                mae = mean_absolute_error(compareDf_val.TrueRank, compareDf_val.RecRank)\n",
    "                all_mae_val.append(mae)\n",
    "\n",
    "            # Store results for each n\n",
    "            outer_jacs_val.append(np.array(all_jacs_val).mean())\n",
    "            outer_cos_val.append(np.array(all_cos_val).mean())\n",
    "            outer_lev_val.append(np.array(all_lev_val).mean())\n",
    "            outer_rmse_val.append(np.array(all_rmse_val).mean())\n",
    "            outer_mae_val.append(np.array(all_mae_val).mean())\n",
    "            outer_jacs.append(np.array(all_jacs).mean())\n",
    "            outer_cos.append(np.array(all_cos).mean())\n",
    "            outer_lev.append(np.array(all_lev).mean())\n",
    "            outer_rmse.append(np.array(all_rmse).mean())\n",
    "            outer_mae.append(np.array(all_mae).mean())\n",
    "\n",
    "        # Store for every sample\n",
    "        plot_jacs_val.append(np.array([np.array(outer_jacs_val)]))\n",
    "        plot_cos_val.append(np.array([np.array(outer_cos_val)]))\n",
    "        plot_lev_val.append(np.array([np.array(outer_lev_val)]))\n",
    "        plot_rmse_val.append(np.array([np.array(outer_rmse_val)]))\n",
    "        plot_mae_val.append(np.array([np.array(outer_mae_val)]))\n",
    "        plot_jacs.append(np.array([np.array(outer_jacs)]))\n",
    "        plot_cos.append(np.array([np.array(outer_cos)]))\n",
    "        plot_lev.append(np.array([np.array(outer_lev)]))\n",
    "        plot_rmse.append(np.array([np.array(outer_rmse)]))\n",
    "        plot_mae.append(np.array([np.array(outer_mae)]))\n",
    "\n",
    "    # Calculate means\n",
    "    # Can perform mean of means here because we care about the inner mean value, and want the mean of it.\n",
    "    output_data_jacs_val = np.array(plot_jacs_val).mean(axis=0)\n",
    "    output_data_cos_val = np.array(plot_cos_val).mean(axis=0)\n",
    "    output_data_lev_val = np.array(plot_lev_val).mean(axis=0)\n",
    "    output_data_rmse_val = np.array(plot_rmse_val).mean(axis=0)\n",
    "    output_data_mae_val = np.array(plot_mae_val).mean(axis=0)\n",
    "    output_data_jacs = np.array(plot_jacs).mean(axis=0)\n",
    "    output_data_cos = np.array(plot_cos).mean(axis=0)\n",
    "    output_data_lev = np.array(plot_lev).mean(axis=0)\n",
    "    output_data_rmse = np.array(plot_rmse).mean(axis=0)\n",
    "    output_data_mae = np.array(plot_mae).mean(axis=0)\n",
    "\n",
    "    # Store for every NN metric\n",
    "    oo_jacs_val.append(output_data_jacs_val)\n",
    "    oo_cos_val.append(output_data_cos_val)\n",
    "    oo_lev_val.append(output_data_lev_val)\n",
    "    oo_rmse_val.append(output_data_rmse_val)\n",
    "    oo_mae_val.append(output_data_mae_val)\n",
    "    oo_jacs.append(output_data_jacs)\n",
    "    oo_cos.append(output_data_cos)\n",
    "    oo_lev.append(output_data_lev)\n",
    "    oo_rmse.append(output_data_rmse)\n",
    "    oo_mae.append(output_data_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2300a369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON VALIDATION SET, \n",
      "Best Metrics for jaccard, cosine, levenshtein, rmse, and mae, respectively\n",
      "______________________\n",
      "cosine\n",
      "Ordered best to worst:\n",
      "['cosine', 'manhattan', 'l2', 'nan_euclidean', 'cityblock', 'l1', 'euclidean']\n",
      "______________________\n",
      "cosine\n",
      "Ordered best to worst:\n",
      "['cosine', 'manhattan', 'l2', 'nan_euclidean', 'cityblock', 'l1', 'euclidean']\n",
      "______________________\n",
      "cityblock\n",
      "Ordered best to worst:\n",
      "['cityblock', 'cosine', 'euclidean', 'l2', 'l1', 'manhattan', 'nan_euclidean']\n",
      "______________________\n",
      "cosine\n",
      "Ordered best to worst:\n",
      "['cosine', 'cityblock', 'l2', 'manhattan', 'euclidean', 'nan_euclidean', 'l1']\n",
      "______________________\n",
      "cosine\n",
      "Ordered best to worst:\n",
      "['cosine', 'cityblock', 'manhattan', 'nan_euclidean', 'l2', 'euclidean', 'l1']\n",
      "\n",
      "Cosine similarity is best in 4/5 metrics (Levenshtein only difference). So, cosine similarity is best to use for Nearest Neighbors\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the NN metrics\n",
    "metric_list_inner = [oo_jacs_val, oo_cos_val, oo_lev_val, oo_rmse_val, oo_mae_val]\n",
    "print(\"ON VALIDATION SET, \")\n",
    "print(\"Best Metrics for jaccard, cosine, levenshtein, rmse, and mae, respectively\")\n",
    "\n",
    "for j, metric in enumerate(metric_list_inner):\n",
    "    print(\"______________________\")\n",
    "    if(j<2): # for similarities\n",
    "        mm = 1# 0 = min, 1 = max\n",
    "    else:\n",
    "        mm = 0\n",
    "    all_vals = []\n",
    "    for i in range(7):\n",
    "        # Show best NN distance metric for each recorded metric on the validation set\n",
    "        # Create list of best values on any N for the given metric\n",
    "        if(mm==1):\n",
    "            all_vals.append(max(metric[i][0]))\n",
    "        else:\n",
    "            all_vals.append(min(metric[i][0]))\n",
    "    if(mm==1):\n",
    "        print(metric_list[np.array(all_vals).argmax()])\n",
    "        print(\"Ordered best to worst:\")\n",
    "        print([metric_list[k] for k in np.array(all_vals).argsort()[-7:][::-1]])\n",
    "    else:\n",
    "        print(metric_list[np.array(all_vals).argmin()])\n",
    "        print(\"Ordered best to worst:\")\n",
    "        print([metric_list[k] for k in np.array(all_vals).argsort()[-7:]])\n",
    "print()\n",
    "print(\"Cosine similarity is best in 4/5 metrics (Levenshtein only difference). So, cosine similarity is best to use for Nearest Neighbors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c078e1d",
   "metadata": {},
   "source": [
    "### Cosine still minimizes MAE at 5, which tells us to use cosine as a metric and 5 as a number of recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f893a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation metric dataframe\n",
    "metricDf_val = pd.DataFrame()\n",
    "metricDf_val[\"JacSim\"] = output_data_jacs_val[0]\n",
    "metricDf_val[\"CosSim\"] = output_data_cos_val[0]\n",
    "metricDf_val[\"LevDis\"] = output_data_lev_val[0]\n",
    "metricDf_val[\"RMSE\"] = output_data_rmse_val[0]\n",
    "metricDf_val[\"MAE\"] = output_data_mae_val[0]\n",
    "metricDf_val[\"NumRec\"] = metricDf_val.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a636a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store as csv\n",
    "metricDf_val.to_csv(\"valMetrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10cff765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test metric dataframe\n",
    "metricDf = pd.DataFrame()\n",
    "metricDf[\"JacSim\"] = output_data_jacs[0]\n",
    "metricDf[\"CosSim\"] = output_data_cos[0]\n",
    "metricDf[\"LevDis\"] = output_data_lev[0]\n",
    "metricDf[\"RMSE\"] = output_data_rmse[0]\n",
    "metricDf[\"MAE\"] = output_data_mae[0]\n",
    "metricDf[\"NumRec\"] = metricDf.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45c1db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store as csv\n",
    "metricDf.to_csv(\"metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a47d3c",
   "metadata": {},
   "source": [
    "### Testing: Given a cart, average cosine sim for each item and display the optimal n (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1e9d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL SYSTEM - USED LIVE AND INCLUDES ALL GIVEN DATA\n",
    "\n",
    "n=5 # 5 pizza recommendations\n",
    "\n",
    "# Initialize and fit the model using best params\n",
    "knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn.fit(itemitem.values)\n",
    "\n",
    "# Store model values\n",
    "distances, indices = knn.kneighbors(itemitem.values, n_neighbors=n+1) #+1 for removal of self similarity\n",
    "\n",
    "# Get a map of the pizza\n",
    "map_pizza = itemitem.index.to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc480eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/m9393pr55dd73xt9k6s7jnlm0000gn/T/ipykernel_70875/2838131429.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  totalDf = totalDf.append(currDf)\n",
      "/var/folders/58/m9393pr55dd73xt9k6s7jnlm0000gn/T/ipykernel_70875/2838131429.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  totalDf = totalDf.append(currDf)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cali_ckn', 0.13534339737958456),\n",
       " ('thai_ckn', 0.1306199792665136),\n",
       " ('pepperoni', 0.12759280601912637),\n",
       " ('southw_ckn', 0.1273504991106329),\n",
       " ('classic_dlx', 0.12360246863054258)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST:\n",
    "# Initialize a cart and number of recommendations\n",
    "cart = [\"bbq_ckn\", \"hawaiian\", \"five_cheese\"]\n",
    "n = 5\n",
    "# Iterate through the cart\n",
    "for i,item in enumerate(cart):\n",
    "    # Select the overall index of the pizza type in the cart\n",
    "    idx = pizza_types.index(item)\n",
    "    # Create a dataframe of model results at this overall index\n",
    "    currDf = pd.DataFrame()\n",
    "    currDf[\"Distance\"] = distances[idx]\n",
    "    currDf[\"Indices\"] = indices[idx]\n",
    "    # Sort by indices\n",
    "    currDf = currDf.sort_values(by=\"Indices\")\n",
    "    # Create total dataframe output\n",
    "    if(i==0):\n",
    "        totalDf = currDf\n",
    "    else:\n",
    "        totalDf = totalDf.append(currDf)\n",
    "\n",
    "# Group the output dataframe by the indices(which map to pizza types) and get the mean distance, then sort by distance ascending\n",
    "distanceDf = totalDf.groupby(\"Indices\").agg({\"Distance\":\"mean\"}).sort_values(by=\"Distance\").reset_index() \n",
    "# Select the pizzas (not in the cart) that are closest/most recommended\n",
    "all_recs = [(pizza_types[i], 1-d) for i,d in zip(distanceDf.Indices,distanceDf.Distance) if pizza_types[i] not in cart]\n",
    "# Diplay the top n pizzas and their similarity\n",
    "all_recs[:n] # similarity shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefc2a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
